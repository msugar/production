{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../05_src/data/prices/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below.\n",
    "\n",
    "# Option 1: Jupyter Notebook magic commands\n",
    "\n",
    "#     %load_ext dotenv\n",
    "#     %dotenv\n",
    "\n",
    "\n",
    "# Option 2: Plain Python code\n",
    "\n",
    "# Load environment variable using dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the PRICE_DATA environment variable\n",
    "PRICE_DATA = os.getenv('PRICE_DATA')\n",
    "PRICE_DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the query planning option on to prevent message\n",
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "    \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Write your code below.\n",
    "\n",
    "# Retrieve the PRICE_DATA environment variable\n",
    "PRICE_DATA = os.getenv('PRICE_DATA')\n",
    "assert os.path.isdir(PRICE_DATA), f\"'{PRICE_DATA=}' is not a valid directory\"\n",
    "\n",
    "# Get all *.parquet files and directories recursively\n",
    "parquet_paths = glob(os.path.join(PRICE_DATA, \"**\", \"*.parquet\"), recursive=True)\n",
    "\n",
    "# Filter to keep only files (exclude directories)\n",
    "parquet_files = [path for path in parquet_paths if os.path.isfile(path)]\n",
    "assert len(parquet_files) == 11207, f\"Expected 11207 files, but found {len(parquet_files)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Adjusted Close:\n",
    "    \n",
    "    - `returns`: (Adj Close / Adj Close_lag) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read all parquet files into a single Dask DataFrame\n",
    "ddf = dd.read_parquet(parquet_files).set_index('ticker')\n",
    "\n",
    "# Provides Dask with a template of the expected output structure, \n",
    "# so it knows the columns and data types without computing the \n",
    "# entire operation immediately.\n",
    "# Not strictly necessary, but it's a nice-to-have.\n",
    "column_types = {\n",
    "    'Date': 'datetime64[ns, UTC]',\n",
    "    'Adj Close': float,\n",
    "    'Close': float,\n",
    "    'High': float,\n",
    "    'Low': float,\n",
    "    'Open': float,\n",
    "    'Volume': np.int64,\n",
    "    'sector': 'string[pyarrow]',\n",
    "    'subsector': 'string[pyarrow]',\n",
    "    'year': 'int32',\n",
    "    'Close_lag': float,\n",
    "    'Adj_Close_lag': float,\n",
    "    'hi_lo_range': float,\n",
    "    'returns': float\n",
    "}\n",
    "meta_df = pd.DataFrame({col: pd.Series(dtype=dt) for col, dt in column_types.items()})\n",
    "\n",
    "# Option 1: Add features using chain of apply(), lambda, and assign()\n",
    "dd_feat = (\n",
    "    ddf.groupby('ticker', group_keys=False)\n",
    "    .apply(\n",
    "        lambda x: x.sort_values('Date').assign(\n",
    "            # Add lags for 'Close' and 'Adj_Close'\n",
    "            Close_lag = x['Close'].shift(1),\n",
    "            Adj_Close_lag = x['Adj Close'].shift(1),\n",
    "\n",
    "            # Calculate the daily high-low range\n",
    "            hi_lo_range = x['High'] - x['Low']\n",
    "        ).assign(\n",
    "            # Calculate returns based on Adjusted Close\n",
    "            returns = lambda x: x['Adj Close'] / x['Adj_Close_lag'] - 1\n",
    "        )\n",
    "        , meta = meta_df\n",
    "    )\n",
    ")\n",
    "\n",
    "# Option 2: Add features with apply() and externally defined function.\n",
    "# (See my Student Notes at the bottom of this notebook for details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a rolling average return calculation with a window of 10 days.\n",
    "+ *Tip*: Consider using `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below.\n",
    "\n",
    "# Convert the Dask DataFrame to a Pandas DataFrame (takes 2m36s on my machine)\n",
    "pd_feat = dd_feat.compute()\n",
    "\n",
    "# [Works] Calculate the 10-day rolling average return using the Pandas dataframe (takes <1s)\n",
    "pd_feat['avg_return_10d'] = pd_feat.groupby('ticker')['returns'].transform(lambda s: s.rolling(10).mean())\n",
    "\n",
    "# [Doesn't work] Calculate the 10-day rolling average return using the Pandas dataframe (takes <1s)\n",
    "# A StackOverflow answer helped me to understand why: https://stackoverflow.com/a/13998600\n",
    "# pd_feat['avg_return_10d'] = pd_feat.groupby('ticker', group_keys=False)['returns'].rolling(window=10).mean().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_nan_pattern(df):\n",
    "    \"\"\"\n",
    "    Verifies that there are exactly 10 NaN values in avg_return_10d per ticker\n",
    "    and that they occur in the first 10 rows of each ticker group.\n",
    "    \n",
    "    Throws an AssertionError otherwise.\n",
    "    \"\"\"\n",
    "    # Group by index (ticker)\n",
    "    grouped = df.groupby(level=0)\n",
    "    \n",
    "    # Get cumulative count within groups\n",
    "    cumcount = grouped.cumcount()\n",
    "    \n",
    "    # Separate first 10 rows and rest\n",
    "    mask_first_10 = cumcount < 10\n",
    "    \n",
    "    # Check if first n rows have NaN values\n",
    "    first_10_nan = df.loc[mask_first_10, 'avg_return_10d'].isna()\n",
    "\n",
    "    # Check if remaining rows have valid values\n",
    "    rest_not_nan = df.loc[~mask_first_10, 'avg_return_10d'].notna()\n",
    "\n",
    "    assert first_10_nan.all(), f\"First 10 rows do not contain all NaN values\"\n",
    "    assert rest_not_nan.all(), f\"Rows after the first 10 contain NaN values\"\n",
    "    \n",
    "verify_nan_pattern(pd_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sector</th>\n",
       "      <th>subsector</th>\n",
       "      <th>year</th>\n",
       "      <th>Close_lag</th>\n",
       "      <th>Adj_Close_lag</th>\n",
       "      <th>hi_lo_range</th>\n",
       "      <th>returns</th>\n",
       "      <th>avg_return_10d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>6.752522</td>\n",
       "      <td>7.5625</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>7.3750</td>\n",
       "      <td>8.3125</td>\n",
       "      <td>1287300</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.339996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-04 00:00:00+00:00</td>\n",
       "      <td>6.808328</td>\n",
       "      <td>7.6250</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>7.3750</td>\n",
       "      <td>7.3750</td>\n",
       "      <td>1238300</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>500.489990</td>\n",
       "      <td>492.875946</td>\n",
       "      <td>16.769989</td>\n",
       "      <td>-0.986187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-05 00:00:00+00:00</td>\n",
       "      <td>6.975746</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>1096300</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>492.119995</td>\n",
       "      <td>484.633331</td>\n",
       "      <td>9.660004</td>\n",
       "      <td>-0.985606</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-06 00:00:00+00:00</td>\n",
       "      <td>7.254776</td>\n",
       "      <td>8.1250</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1026700</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>488.019989</td>\n",
       "      <td>480.595673</td>\n",
       "      <td>6.630005</td>\n",
       "      <td>-0.984905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-07 00:00:00+00:00</td>\n",
       "      <td>7.812836</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>9.1250</td>\n",
       "      <td>8.0625</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>2419300</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>492.540009</td>\n",
       "      <td>485.046906</td>\n",
       "      <td>20.029999</td>\n",
       "      <td>-0.983893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-10 00:00:00+00:00</td>\n",
       "      <td>7.477999</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>8.9375</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>8.8750</td>\n",
       "      <td>1276200</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>481.709991</td>\n",
       "      <td>474.381653</td>\n",
       "      <td>7.389984</td>\n",
       "      <td>-0.984236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-11 00:00:00+00:00</td>\n",
       "      <td>7.366389</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>693700</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>481.589996</td>\n",
       "      <td>474.263489</td>\n",
       "      <td>12.569977</td>\n",
       "      <td>-0.984468</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-12 00:00:00+00:00</td>\n",
       "      <td>7.533803</td>\n",
       "      <td>8.4375</td>\n",
       "      <td>8.6875</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>764000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>485.499908</td>\n",
       "      <td>13.269989</td>\n",
       "      <td>-0.984482</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-13 00:00:00+00:00</td>\n",
       "      <td>8.259281</td>\n",
       "      <td>9.2500</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>8.5625</td>\n",
       "      <td>8.5625</td>\n",
       "      <td>1760600</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>494.290009</td>\n",
       "      <td>486.770294</td>\n",
       "      <td>15.459991</td>\n",
       "      <td>-0.983032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-14 00:00:00+00:00</td>\n",
       "      <td>7.366389</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>9.3750</td>\n",
       "      <td>1429000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>491.359985</td>\n",
       "      <td>483.884827</td>\n",
       "      <td>5.200012</td>\n",
       "      <td>-0.984777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-18 00:00:00+00:00</td>\n",
       "      <td>7.701226</td>\n",
       "      <td>8.6250</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>776600</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>490.459991</td>\n",
       "      <td>482.998535</td>\n",
       "      <td>9.690002</td>\n",
       "      <td>-0.984055</td>\n",
       "      <td>-0.984564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-19 00:00:00+00:00</td>\n",
       "      <td>7.143163</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>8.6875</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>8.6875</td>\n",
       "      <td>1220100</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>484.750000</td>\n",
       "      <td>477.375397</td>\n",
       "      <td>10.070007</td>\n",
       "      <td>-0.985037</td>\n",
       "      <td>-0.984449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-20 00:00:00+00:00</td>\n",
       "      <td>6.919940</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>8.0625</td>\n",
       "      <td>7.6875</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>1744500</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>491.720001</td>\n",
       "      <td>484.239380</td>\n",
       "      <td>7.040009</td>\n",
       "      <td>-0.985710</td>\n",
       "      <td>-0.984459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-21 00:00:00+00:00</td>\n",
       "      <td>6.975746</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>8.0625</td>\n",
       "      <td>7.6875</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1670100</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>497.299988</td>\n",
       "      <td>489.734467</td>\n",
       "      <td>7.580017</td>\n",
       "      <td>-0.985756</td>\n",
       "      <td>-0.984545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>2000-01-24 00:00:00+00:00</td>\n",
       "      <td>7.087358</td>\n",
       "      <td>7.9375</td>\n",
       "      <td>8.1250</td>\n",
       "      <td>7.6250</td>\n",
       "      <td>7.9375</td>\n",
       "      <td>1001400</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Managed Health Care</td>\n",
       "      <td>2000</td>\n",
       "      <td>494.549988</td>\n",
       "      <td>487.026337</td>\n",
       "      <td>11.259979</td>\n",
       "      <td>-0.985448</td>\n",
       "      <td>-0.984700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Date  Adj Close   Close    High     Low    Open  \\\n",
       "ticker                                                                        \n",
       "HUM    2000-01-03 00:00:00+00:00   6.752522  7.5625  8.3750  7.3750  8.3125   \n",
       "HUM    2000-01-04 00:00:00+00:00   6.808328  7.6250  7.8750  7.3750  7.3750   \n",
       "HUM    2000-01-05 00:00:00+00:00   6.975746  7.8125  7.8750  7.5000  7.5000   \n",
       "HUM    2000-01-06 00:00:00+00:00   7.254776  8.1250  8.2500  7.5000  7.7500   \n",
       "HUM    2000-01-07 00:00:00+00:00   7.812836  8.7500  9.1250  8.0625  8.1875   \n",
       "HUM    2000-01-10 00:00:00+00:00   7.477999  8.3750  8.9375  8.3750  8.8750   \n",
       "HUM    2000-01-11 00:00:00+00:00   7.366389  8.2500  8.7500  8.2500  8.3750   \n",
       "HUM    2000-01-12 00:00:00+00:00   7.533803  8.4375  8.6875  8.2500  8.3750   \n",
       "HUM    2000-01-13 00:00:00+00:00   8.259281  9.2500  9.5000  8.5625  8.5625   \n",
       "HUM    2000-01-14 00:00:00+00:00   7.366389  8.2500  9.6250  8.2500  9.3750   \n",
       "HUM    2000-01-18 00:00:00+00:00   7.701226  8.6250  9.0000  8.3750  9.0000   \n",
       "HUM    2000-01-19 00:00:00+00:00   7.143163  8.0000  8.6875  8.0000  8.6875   \n",
       "HUM    2000-01-20 00:00:00+00:00   6.919940  7.7500  8.0625  7.6875  8.0000   \n",
       "HUM    2000-01-21 00:00:00+00:00   6.975746  7.8125  8.0625  7.6875  7.7500   \n",
       "HUM    2000-01-24 00:00:00+00:00   7.087358  7.9375  8.1250  7.6250  7.9375   \n",
       "\n",
       "Price    Volume       sector            subsector  year   Close_lag  \\\n",
       "ticker                                                                \n",
       "HUM     1287300  Health Care  Managed Health Care  2000         NaN   \n",
       "HUM     1238300  Health Care  Managed Health Care  2000  500.489990   \n",
       "HUM     1096300  Health Care  Managed Health Care  2000  492.119995   \n",
       "HUM     1026700  Health Care  Managed Health Care  2000  488.019989   \n",
       "HUM     2419300  Health Care  Managed Health Care  2000  492.540009   \n",
       "HUM     1276200  Health Care  Managed Health Care  2000  481.709991   \n",
       "HUM      693700  Health Care  Managed Health Care  2000  481.589996   \n",
       "HUM      764000  Health Care  Managed Health Care  2000  493.000000   \n",
       "HUM     1760600  Health Care  Managed Health Care  2000  494.290009   \n",
       "HUM     1429000  Health Care  Managed Health Care  2000  491.359985   \n",
       "HUM      776600  Health Care  Managed Health Care  2000  490.459991   \n",
       "HUM     1220100  Health Care  Managed Health Care  2000  484.750000   \n",
       "HUM     1744500  Health Care  Managed Health Care  2000  491.720001   \n",
       "HUM     1670100  Health Care  Managed Health Care  2000  497.299988   \n",
       "HUM     1001400  Health Care  Managed Health Care  2000  494.549988   \n",
       "\n",
       "Price   Adj_Close_lag  hi_lo_range   returns  avg_return_10d  \n",
       "ticker                                                        \n",
       "HUM               NaN    21.339996       NaN             NaN  \n",
       "HUM        492.875946    16.769989 -0.986187             NaN  \n",
       "HUM        484.633331     9.660004 -0.985606             NaN  \n",
       "HUM        480.595673     6.630005 -0.984905             NaN  \n",
       "HUM        485.046906    20.029999 -0.983893             NaN  \n",
       "HUM        474.381653     7.389984 -0.984236             NaN  \n",
       "HUM        474.263489    12.569977 -0.984468             NaN  \n",
       "HUM        485.499908    13.269989 -0.984482             NaN  \n",
       "HUM        486.770294    15.459991 -0.983032             NaN  \n",
       "HUM        483.884827     5.200012 -0.984777             NaN  \n",
       "HUM        482.998535     9.690002 -0.984055       -0.984564  \n",
       "HUM        477.375397    10.070007 -0.985037       -0.984449  \n",
       "HUM        484.239380     7.040009 -0.985710       -0.984459  \n",
       "HUM        489.734467     7.580017 -0.985756       -0.984545  \n",
       "HUM        487.026337    11.259979 -0.985448       -0.984700  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_feat.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was it necessary to convert to Pandas to calculate the moving average return?\n",
    "\n",
    "No, it wasn't strictly necessary to convert to Pandas to calculate the moving average return. Dask has support for rolling operations, so we could have calculated it directly within Dask without converting.\n",
    "\n",
    "### Would it have been better to do it in Dask? Why?\n",
    "\n",
    "No, in this particular case it would not, because the data fits in memory and the computation is fast [1].\n",
    "\n",
    "In addition, using Dask for rolling window operations is not as convenient as doing it in Pandas. With Dask, you should ensure that the partition sizes you choose are large enough to avoid boundary issues, but keep in mind that larger partitions can begin to slow down your computations. The data should also be index-aligned to ensure that itâ€™s sorted in the correct order. Dask uses the index to determine which rows are adjacent to one another, so ensuring proper sort order is critical for the correct execution of any calculations on the data. [2]\n",
    "\n",
    "References:\n",
    "- [1] Dask. (n.d.). *Dask DataFrame*. Retrieved October 27, 2024, from [https://docs.dask.org/en/stable/dataframe.html#when-not-to-use-dask-dataframes](https://docs.dask.org/en/stable/dataframe.html#when-not-to-use-dask-dataframes)\n",
    "- [2] Daniel, J. C. (2019). *Data science with Python and Dask* (p. 161). Manning Publications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ x ] Created a branch with the correct naming convention.\n",
    "- [ x ] Ensured that the repository is public.\n",
    "- [ x ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ x ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Notes\n",
    "\n",
    "*Option 2: Add features with apply() and externally defined function*\n",
    "\n",
    "This option only works when the function is defined outside the Jupyter notebook, otherwise Dask throws an error: \n",
    "```\n",
    "Function ... may not be deterministically hashed by cloudpickle\n",
    "```\n",
    "Here are the steps to use this approach:\n",
    "1. Define the function in its own source file, outside the notebook. For example, in `${SRC_DIR}/feature_engineering.py`:\n",
    "    ```python\n",
    "    # For each ticker, add lags, returns, and high-low range\n",
    "    def add_features(df):\n",
    "        # Sort by date if not already sorted\n",
    "        #df = df.sort_index()\n",
    "        \n",
    "        # Add lags for 'Close' and 'Adj_Close'\n",
    "        df['Close_lag'] = df['Close'].shift(1)\n",
    "        df['Adj_Close_lag'] = df['Adj Close'].shift(1)\n",
    "        \n",
    "        # Calculate returns based on Adjusted Close\n",
    "        df['returns'] = (df['Adj Close'] / df['Adj_Close_lag']) - 1\n",
    "        \n",
    "        # Calculate the daily high-low range\n",
    "        df['hi_lo_range'] = df['High'] - df['Low']\n",
    "        \n",
    "        return df\n",
    "    ```\n",
    "\n",
    "2. In the notebook, import the externally defined function and apply it to each group of the Dask dataframe:\n",
    "    ```python\n",
    "    import sys\n",
    "    sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "    from feature_engineering import add_features\n",
    "\n",
    "    dd_feat = ddf.groupby('ticker', group_keys=False).apply(add_features, meta=ddf)\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
